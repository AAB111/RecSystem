{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Word2Vec\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark-3.5.1/conf/spark-env.sh: строка 1: !/usr/bin/bash: Нет такого файла или каталога\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/15 21:00:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/15 21:00:53 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"/home/aleksey/Документы/RecSystem\")\n",
    "from config import settings\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"DB\")\n",
    "    .config(\"spark.driver.extraClassPath\",\"/usr/lib/spark-3.5.1/jars/postgresql-42.7.0.jar\")\n",
    "    .getOrCreate())\n",
    "\n",
    "movie = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"url\", f\"jdbc:postgresql://{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}\")\n",
    "    .option(\"dbtable\", f'\"{settings.DB_SCHEMA}\".\"Movie\"')\n",
    "    .option(\"user\", settings.DB_USER)\n",
    "    .option(\"password\", settings.DB_PASS)\n",
    "    .load())\n",
    "\n",
    "genre_movie = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"url\", f\"jdbc:postgresql://{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}\")\n",
    "    .option(\"dbtable\", f'\"{settings.DB_SCHEMA}\".\"GenreMovie\"')\n",
    "    .option(\"user\", settings.DB_USER)\n",
    "    .option(\"password\", settings.DB_PASS)\n",
    "    .load())\n",
    "\n",
    "genre = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"url\", f\"jdbc:postgresql://{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}\") \\\n",
    "    .option(\"dbtable\", f'\"{settings.DB_SCHEMA}\".\"Genre\"') \\\n",
    "    .option(\"user\", settings.DB_USER) \\\n",
    "    .option(\"password\", settings.DB_PASS) \\\n",
    "    .load()\n",
    "\n",
    "keyword_movie = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"url\", f\"jdbc:postgresql://{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}\")\n",
    "    .option(\"dbtable\", f'\"{settings.DB_SCHEMA}\".\"KeywordMovie\"')\n",
    "    .option(\"user\", settings.DB_USER)\n",
    "    .option(\"password\", settings.DB_PASS)\n",
    "    .load())\n",
    "\n",
    "keyword = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"url\", f\"jdbc:postgresql://{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}\")\n",
    "    .option(\"dbtable\", f'\"{settings.DB_SCHEMA}\".\"Keyword\"')\n",
    "    .option(\"user\", settings.DB_USER)\n",
    "    .option(\"password\", settings.DB_PASS)\n",
    "    .load())\n",
    "\n",
    "person = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"url\", f\"jdbc:postgresql://{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}\")\n",
    "    .option(\"dbtable\", f'\"{settings.DB_SCHEMA}\".\"Person\"')\n",
    "    .option(\"user\", settings.DB_USER)\n",
    "    .option(\"password\", settings.DB_PASS)\n",
    "    .load())\n",
    "\n",
    "crew = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"url\", f\"jdbc:postgresql://{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}\")\n",
    "    .option(\"dbtable\", f'\"{settings.DB_SCHEMA}\".\"Crew\"')\n",
    "    .option(\"user\", settings.DB_USER)\n",
    "    .option(\"password\", settings.DB_PASS)\n",
    "    .load())\n",
    "\n",
    "cast = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"url\", f\"jdbc:postgresql://{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}\")\n",
    "    .option(\"dbtable\", f'\"{settings.DB_SCHEMA}\".\"Cast\"')\n",
    "    .option(\"user\", settings.DB_USER)\n",
    "    .option(\"password\", settings.DB_PASS)\n",
    "    .load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType, DoubleType\n",
    "@F.udf(returnType=DoubleType())\n",
    "def cos_sim(u, v):\n",
    "  return float(u.dot(v) / (u.norm(2) * v.norm(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_sim(dataframe, description_var):\n",
    "    tokenizer = RegexTokenizer(inputCol=description_var, outputCol=\"words\", pattern=\"\\\\W\")\n",
    "    remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "    hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "    idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "    normalizer = Normalizer(inputCol=\"features\", outputCol=\"normalized_features\")\n",
    "    \n",
    "    pipeline = Pipeline(stages=[tokenizer, remover, hashing_tf,idf,normalizer])\n",
    "    model = pipeline.fit(dataframe)\n",
    "    transformed_df = model.transform(dataframe)\n",
    "    transformed_df = transformed_df.drop('filtered_words','raw_features','words','features')\n",
    "    postfix = 'right'\n",
    "    transformed_df = transformed_df.crossJoin(transformed_df\n",
    "                                              .select([F.col(c).alias(f'{c}_{postfix}') for c in transformed_df.columns]))\n",
    "    transformed_df = transformed_df.withColumn('cos_sim',cos_sim(F.col('normalized_features'),F.col(f'normalized_features_{postfix}')))\n",
    "    return transformed_df\n",
    "\n",
    "def content_based_recommender(dataframe, movie_id, similarity_matrix,top_n=10):\n",
    "    similar_movies = (similarity_matrix.filter(F.col('id') == movie_id)\n",
    "        .sort(F.col('cos_sim').desc())\n",
    "        .limit(top_n + 1))\n",
    "    similar_movie_indices = similar_movies.select('id_right').collect()[1:]\n",
    "    similar_movie_indices = [row['id_right'] for row in similar_movie_indices]\n",
    "    \n",
    "    return (dataframe.filter(F.col(\"id\").isin(similar_movie_indices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movie = movie.withColumn(\"combined_column\", F.concat(movie[\"title\"], F.lit(\" \"), movie[\"tagline\"], F.lit(\" \"), movie[\"overview\"]))\n",
    "\n",
    "cosine_sim = calculate_cosine_sim(movie.select('id','combined_column'), \"combined_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/15 20:43:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "[Stage 14:>                 (0 + 1) / 1][Stage 17:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+------------------+--------------------+\n",
      "|     id|               title|             tagline|            overview|         poster_path|original_language|release_date|runtime|        popularity|vote_count|      vote_average|     combined_column|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+------------------+--------------------+\n",
      "|   4233|            Scream 2|Someone has taken...|Away at college, ...|/isdgZMoH1QMpfvzM...|               en|  1997-12-12|    120| 71.05599975585938|      3926|               6.5|Scream 2 Someone ...|\n",
      "|   4234|            Scream 3|The most terrifyi...|While Sidney Pres...|/qpH8ToZVlFD1bakL...|               en|  2000-02-04|    117| 46.49399948120117|      3379|               6.0|Scream 3 The most...|\n",
      "|   4247|         Scary Movie|No mercy. No sham...|A familiar-lookin...|/lRQiJXETkCnVVurH...|               en|  2000-07-07|     88| 58.38999938964844|      6643| 6.353000164031982|Scary Movie No me...|\n",
      "|   4248|       Scary Movie 2|More merciless. M...|While the origina...|/7Eb1JWK0Cb0rbfsY...|               en|  2001-07-04|     83|  53.7239990234375|      4434| 5.794000148773193|Scary Movie 2 Mor...|\n",
      "|  41446|            Scream 4|New decade. New r...|Sidney Prescott, ...|/qeonDYVASBKeC0bn...|               en|  2011-04-13|    111| 40.92900085449219|      3505|               6.5|Scream 4 New deca...|\n",
      "| 106021|              Erased|Far from home. Fa...|A former agent of...|/m9pUIC2lp40KvDxd...|               en|  2012-08-23|    100|23.329999923706055|       695| 6.071000099182129|Erased Far from h...|\n",
      "| 353066|The Vanishing of ...|It's all about be...|Over the course o...|/e8SJJEliAK9g0EG5...|               en|  2018-03-02|    117|              20.0|       241|6.7179999351501465|The Vanishing of ...|\n",
      "| 637693|      Spirit Untamed|   Adventure awaits.|Lucky Prescott's ...|/q4WaFHk9Vp1poc88...|               en|  2021-05-20|     88|  39.0890007019043|       495| 7.244999885559082|Spirit Untamed Ad...|\n",
      "| 961722|              Sidney|The life and the ...|This revealing do...|/cVdkjqmIipF2DCvD...|               en|  2022-09-10|    112| 7.414999961853027|        21| 7.800000190734863|Sidney The life a...|\n",
      "|1127175|         Mercy Falls|How far would you...|A group of friend...|/aNiAEjTebmwJtTx9...|               en|  2023-09-01|    104| 6.818999767303467|         9|               5.5|Mercy Falls How f...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "content_based_recommender(movie, 4232, cosine_sim).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination_tto_genres_keywords_actors_directors(movie):\n",
    "    joined_df = movie.join(genre_movie, movie[\"id\"] == genre_movie[\"movie_id\"], \"left\")\n",
    "\n",
    "    movie_genre = joined_df.join(genre, genre_movie[\"genre_id\"] == genre[\"id\"], \"left\")\n",
    "\n",
    "    movie_genre = (movie_genre\n",
    "                .select(movie.id, movie.title,movie.tagline,movie.overview, genre.name)\n",
    "                .groupBy(movie.id, movie.title,movie.tagline,movie.overview).agg(F.collect_list(genre.name).alias(\"genres\")))\n",
    "    \n",
    "    movie_keyword = movie_genre.join(keyword_movie, movie[\"id\"] == keyword_movie[\"movie_id\"], \"left\")\n",
    "    movie_keyword = movie_keyword.join(keyword,movie_keyword[\"keyword_id\"] == keyword[\"id\"],\"left\")\n",
    "    movie_keyword = (movie_keyword\n",
    "                    .select(movie_genre.id,movie_genre.title,movie_genre.tagline,movie_genre.overview,movie_genre.genres,keyword.name.alias(\"keyword_name\"))\n",
    "                    .groupBy(movie_genre.id,movie_genre.title,movie_genre.tagline,movie_genre.overview,movie_genre.genres).agg(F.collect_list('keyword_name').alias(\"keywords\"))\n",
    "                    )\n",
    "    \n",
    "    joined_data = crew.join(person, crew[\"person_id\"] == person[\"id\"], \"left\")\n",
    "    directors = joined_data.filter(F.col(\"job\") == \"Director\").select(crew.movie_id,person.name,).groupBy(\"movie_id\").agg(\n",
    "        F.collect_list(\"name\").alias(\"directors\")\n",
    "    )\n",
    "\n",
    "    joined_data = cast.join(person, cast[\"person_id\"] == person[\"id\"], \"left\")\n",
    "    window_spec = Window.partitionBy(\"movie_id\").orderBy(F.desc(\"popularity\"))\n",
    "    top_actors = (joined_data.withColumn(\"rank\", F.row_number().over(window_spec))\n",
    "                .filter(F.col(\"rank\") <= 3)\n",
    "                .select(cast.movie_id,person.name.alias(\"actor_name\")))\n",
    "    top_actors = (top_actors.\n",
    "                groupBy(\"movie_id\").agg(\n",
    "                F.collect_list(\"actor_name\").alias(\"actors\")\n",
    "    ))\n",
    "\n",
    "    movie_actors = movie_keyword.join(top_actors, top_actors[\"movie_id\"] == movie_keyword[\"id\"], \"left\")\n",
    "    movie_actors_directors = movie_actors.join(directors,directors['movie_id'] == movie_actors['id'],'left')\n",
    "    \n",
    "    movie_actors_directors = movie_actors_directors.select('id','title','tagline','overview','genres','keywords','actors','directors')\n",
    "    movie_actors_directors = (movie_actors_directors\n",
    "                                    .withColumn(\"combined_column\",\n",
    "                                      F.concat_ws(\" \", *[F.col(c) for c in movie_actors_directors.columns if c != 'id'])))\n",
    "    return movie_actors_directors.select('id','combined_column')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movie_genres_keywords = combination_tto_genres_keywords_actors_directors(movie)\n",
    "cosine_sim = calculate_cosine_sim(movie_genres_keywords.select('id','combined_column'), \"combined_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/15 17:47:36 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "[Stage 1320:=================================================>      (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "|    id|               title|             tagline|            overview|         poster_path|original_language|release_date|runtime|        popularity|vote_count|     vote_average|     combined_column|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "|   948|           Halloween|The Night He Came...|Fifteen years aft...|/wijlZ3HaYMvlDTPq...|               en|  1978-10-24|     91| 78.03600311279297|      5286|7.557000160217285|Halloween The Nig...|\n",
      "|  4233|            Scream 2|Someone has taken...|Away at college, ...|/isdgZMoH1QMpfvzM...|               en|  1997-12-12|    120| 71.05599975585938|      3926|              6.5|Scream 2 Someone ...|\n",
      "|  4234|            Scream 3|The most terrifyi...|While Sidney Pres...|/qpH8ToZVlFD1bakL...|               en|  2000-02-04|    117| 46.49399948120117|      3379|              6.0|Scream 3 The most...|\n",
      "| 41446|            Scream 4|New decade. New r...|Sidney Prescott, ...|/qeonDYVASBKeC0bn...|               en|  2011-04-13|    111| 40.92900085449219|      3505|              6.5|Scream 4 New deca...|\n",
      "| 83938|Scream: The Insid...|                    |In 1996, the horr...|/5kT5M0GV2ijsR4a7...|               en|  2011-04-06|     90| 4.513999938964844|        20|6.199999809265137|Scream: The Insid...|\n",
      "|424139|           Halloween|     Face Your Fate.|Laurie Strode com...|/f7JAX5EGk4GgsEnu...|               en|  2018-10-18|    106| 55.23699951171875|      4500|6.552000045776367|Halloween Face Yo...|\n",
      "|616820|      Halloween Ends|Only one of them ...|Four years after ...|/q06saepaXeBdkMib...|               en|  2022-10-12|    111| 53.31100082397461|      1597| 6.13700008392334|Halloween Ends On...|\n",
      "|628707|               Trick| Always choose treat|A detective tries...|/k1Ft0smy9XjyMq1H...|               en|  2019-10-18|    101|29.166000366210938|       136|5.900000095367432|Trick Always choo...|\n",
      "|646385|              Scream|It's always someo...|Twenty-five years...|/1m3W6cpgwuIyjtg5...|               en|  2022-01-12|    114| 71.06199645996094|      3047|6.699999809265137|Scream It's alway...|\n",
      "|934433|           Scream VI|New York. New rules.|Following the lat...|/wDWwtvkRRlgTiUr6...|               en|  2023-03-08|    123|114.93800354003906|      2304|7.099999904632568|Scream VI New Yor...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_based_recommender(movie, 4232, cosine_sim).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination_genres_keywords(movie):\n",
    "  joined_df = movie.join(genre_movie, movie[\"id\"] == genre_movie[\"movie_id\"], \"left\")\n",
    "  \n",
    "  movie_genre = joined_df.join(genre, genre_movie[\"genre_id\"] == genre[\"id\"], \"left\")\n",
    "\n",
    "  movie_genre = (movie_genre\n",
    "              .select(movie.id, genre.name)\n",
    "              .groupBy(movie.id).agg(F.collect_list(genre.name).alias(\"genres\")))\n",
    "  \n",
    "  movie_keyword = movie_genre.join(keyword_movie, movie[\"id\"] == keyword_movie[\"movie_id\"], \"left\")\n",
    "  movie_keyword = movie_keyword.join(keyword,movie_keyword[\"keyword_id\"] == keyword[\"id\"],\"left\")\n",
    "  movie_keyword = (movie_keyword\n",
    "                  .select(movie_genre.id,movie_genre.genres,keyword.name.alias(\"keyword_name\"))\n",
    "                  .groupBy(movie_genre.id,movie_genre.genres).agg(F.collect_list('keyword_name').alias(\"keywords\"))\n",
    "                  )\n",
    "  \n",
    "  movie_genres_keywords = (movie_keyword\n",
    "                                  .withColumn(\"combined_column\",\n",
    "                                    F.concat_ws(\" \", *[F.col(c) for c in movie_keyword.columns if c != 'id'])))\n",
    "  return movie_genres_keywords.select('id','combined_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movie_genres_keywords = combination_genres_keywords(movie)\n",
    "cosine_sim = calculate_cosine_sim(movie_genres_keywords.select('id','combined_column'), \"combined_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/15 23:38:19 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/04/15 23:38:20 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "/tmp/ipykernel_2606/1708577222.py:4: RuntimeWarning: invalid value encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "|    id|               title|             tagline|            overview|         poster_path|original_language|release_date|runtime|        popularity|vote_count|     vote_average|     combined_column|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "| 50472|Anplagghed al cinema|                    |A queue at the AT...|/eUese3BGFCRFPV8r...|               it|  2006-11-26|     95| 6.021999835968018|       327|              7.0|Anplagghed al cin...|\n",
      "| 67677|Golkonda High School|                    |Set on the backdr...|/eRrjxoAD6IGrcmxt...|               te|  2011-01-14|    130|  2.74399995803833|         3|              7.0|Golkonda High Sch...|\n",
      "| 80983|Ata Demirer Tek K...|                    |Between 2007 and ...|/3uC4J7zkUR7PMAOt...|               tr|  2011-07-01|    101| 1.340000033378601|        13|6.599999904632568|Ata Demirer Tek K...|\n",
      "| 81550| Ice Cream, I Scream|                    |Ali, who is ice c...|/8Ja7DZtvZdiLSxHr...|               tr|  2006-11-24|    100|2.4210000038146973|        48|6.199999809265137|Ice Cream, I Scre...|\n",
      "| 83565|Bana Bir Şeyhler ...|                    |“Anlatacaklarım v...|/vVcAEnGjYAPOn4pw...|               tr|  2003-12-05|    151|1.9559999704360962|        19|7.400000095367432|Bana Bir Şeyhler ...|\n",
      "| 97356|             Astitva|Is a Woman's Dest...|When Aditi finds ...|/uGAGCthCBGMuRuoK...|               hi|  2000-10-06|    109|1.9989999532699585|         5|5.900000095367432|Astitva Is a Woma...|\n",
      "|103386|     Bibo and Beshir|     Bibo and Beshir|The film belongs ...|/lrjbQxn5E2N9YQrP...|               ar|  2011-08-30|    119| 2.063999891281128|         9|6.800000190734863|Bibo and Beshir B...|\n",
      "|107889|     The Pomegranate|                    |“The Pomegranate”...|/18aR5q4SSciHoC1z...|               tr|  2011-12-23|     81|0.9430000185966492|        11|5.800000190734863|The Pomegranate  ...|\n",
      "|126863|Tom, Tom, the Pip...|                    |An experimental f...|/3qB5PfgjyBGeWkFP...|               en|  1969-04-11|    115| 1.718000054359436|        14|              6.0|Tom, Tom, the Pip...|\n",
      "|127636| La mujer del puerto|                    |Perla, a prostitu...|/1rQwTSeiNw5C0PfE...|               es|  1991-09-11|    110|1.5369999408721924|        10|5.699999809265137|La mujer del puer...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_based_recommender(movie, 218, cosine_sim).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination_tto_keywords_actors_directors(movie):\n",
    "    movie_keyword = movie.join(keyword_movie, movie[\"id\"] == keyword_movie[\"movie_id\"], \"left\")\n",
    "    movie_keyword = movie_keyword.join(keyword,movie_keyword[\"keyword_id\"] == keyword[\"id\"],\"left\")\n",
    "    movie_keyword = (movie_keyword\n",
    "                    .select(movie.id,movie.title,movie.tagline,movie.overview,keyword.name.alias(\"keyword_name\"))\n",
    "                    .groupBy(movie.id,movie.title,movie.tagline,movie.overview).agg(F.collect_list('keyword_name').alias(\"keywords\"))\n",
    "                    )\n",
    "    \n",
    "    joined_data = crew.join(person, crew[\"person_id\"] == person[\"id\"], \"left\")\n",
    "    directors = joined_data.filter(F.col(\"job\") == \"Director\").select(crew.movie_id,person.name,).groupBy(\"movie_id\").agg(\n",
    "        F.collect_list(\"name\").alias(\"directors\")\n",
    "    )\n",
    "\n",
    "    joined_data = cast.join(person, cast[\"person_id\"] == person[\"id\"], \"left\")\n",
    "    window_spec = Window.partitionBy(\"movie_id\").orderBy(F.desc(\"popularity\"))\n",
    "    top_actors = (joined_data.withColumn(\"rank\", F.row_number().over(window_spec))\n",
    "                .filter(F.col(\"rank\") <= 3)\n",
    "                .select(cast.movie_id,person.name.alias(\"actor_name\")))\n",
    "    top_actors = (top_actors.\n",
    "                groupBy(\"movie_id\").agg(\n",
    "                F.collect_list(\"actor_name\").alias(\"actors\")\n",
    "    ))\n",
    "\n",
    "    movie_actors = movie_keyword.join(top_actors, top_actors[\"movie_id\"] == movie_keyword[\"id\"], \"left\")\n",
    "    movie_actors_directors_keywords = movie_actors.join(directors,directors['movie_id'] == movie_actors['id'],'left')\n",
    "\n",
    "    movie_actors_directors_keywords = movie_actors_directors_keywords.select('id','title','tagline','overview','keywords','actors','directors')\n",
    "\n",
    "    movie_actors_directors_keywords = (movie_actors_directors_keywords\n",
    "                                    .withColumn(\"combined_column\",\n",
    "                                      F.concat_ws(\" \", *[F.col(c) for c in movie_keyword.columns if c != 'id'])))\n",
    "    \n",
    "    return movie_actors_directors_keywords.select('id','combined_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_actors_directors = combination_tto_keywords_actors_directors(movie)\n",
    "# cosine_sim = calculate_cosine_sim(movie_actors_directors_keywords.select('id','combined_column'), \"combined_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|         title|             tagline|            overview|            keywords|              actors|           directors|     combined_column|\n",
      "+---+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 27|       9 Songs|2 lovers, one sum...|Matt, a young gla...|[blowjob, small b...|[Margo Stilley, K...|[Michael Winterbo...|9 Songs 2 lovers,...|\n",
      "| 28|Apocalypse Now|  This is the end...|At the height of ...|[anti war, milita...|[Laurence Fishbur...|[Francis Ford Cop...|Apocalypse Now Th...|\n",
      "| 65|        8 Mile|Every Moment Is A...|For Jimmy Smith, ...|[battle rap, 1990...|[Anthony Mackie, ...|     [Curtis Hanson]|8 Mile Every Mome...|\n",
      "| 76|Before Sunrise|Can the greatest ...|A young man and w...|[romantic, vienna...|[Ethan Hawke, Ada...| [Richard Linklater]|Before Sunrise Ca...|\n",
      "| 78|  Blade Runner|Man has made his ...|In the smog-choke...|[2010s, blade run...|[Harrison Ford, D...|      [Ridley Scott]|Blade Runner Man ...|\n",
      "+---+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_actors_directors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/15 17:46:23 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/04/15 17:46:23 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "[Stage 1234:=================================================>      (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "|    id|          title|             tagline|            overview|         poster_path|original_language|release_date|runtime|        popularity|vote_count|     vote_average|     combined_column|\n",
      "+------+---------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "|   948|      Halloween|The Night He Came...|Fifteen years aft...|/wijlZ3HaYMvlDTPq...|               en|  1978-10-24|     91| 78.03600311279297|      5286|7.557000160217285|Halloween The Nig...|\n",
      "|  4233|       Scream 2|Someone has taken...|Away at college, ...|/isdgZMoH1QMpfvzM...|               en|  1997-12-12|    120| 71.05599975585938|      3926|              6.5|Scream 2 Someone ...|\n",
      "|  4234|       Scream 3|The most terrifyi...|While Sidney Pres...|/qpH8ToZVlFD1bakL...|               en|  2000-02-04|    117| 46.49399948120117|      3379|              6.0|Scream 3 The most...|\n",
      "| 41446|       Scream 4|New decade. New r...|Sidney Prescott, ...|/qeonDYVASBKeC0bn...|               en|  2011-04-13|    111| 40.92900085449219|      3505|              6.5|Scream 4 New deca...|\n",
      "|424139|      Halloween|     Face Your Fate.|Laurie Strode com...|/f7JAX5EGk4GgsEnu...|               en|  2018-10-18|    106| 55.23699951171875|      4500|6.552000045776367|Halloween Face Yo...|\n",
      "|610253|Halloween Kills|  Evil dies tonight.|Michael manages t...|/4CclCDyQXBBgz62Q...|               en|  2021-10-14|    105| 36.35200119018555|      2524|6.456999778747559|Halloween Kills E...|\n",
      "|616820| Halloween Ends|Only one of them ...|Four years after ...|/q06saepaXeBdkMib...|               en|  2022-10-12|    111| 53.31100082397461|      1597| 6.13700008392334|Halloween Ends On...|\n",
      "|628707|          Trick| Always choose treat|A detective tries...|/k1Ft0smy9XjyMq1H...|               en|  2019-10-18|    101|29.166000366210938|       136|5.900000095367432|Trick Always choo...|\n",
      "|646385|         Scream|It's always someo...|Twenty-five years...|/1m3W6cpgwuIyjtg5...|               en|  2022-01-12|    114| 71.06199645996094|      3047|6.699999809265137|Scream It's alway...|\n",
      "|934433|      Scream VI|New York. New rules.|Following the lat...|/wDWwtvkRRlgTiUr6...|               en|  2023-03-08|    123|114.93800354003906|      2304|7.099999904632568|Scream VI New Yor...|\n",
      "+------+---------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+-----------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_based_recommender(movie, 4232, cosine_sim).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------------------+--------------------+--------------------+-----------------+------------+-------+-----------------+----------+-----------------+--------------------+\n",
      "|    id| title|             tagline|            overview|         poster_path|original_language|release_date|runtime|       popularity|vote_count|     vote_average|     combined_column|\n",
      "+------+------+--------------------+--------------------+--------------------+-----------------+------------+-------+-----------------+----------+-----------------+--------------------+\n",
      "|  4232|Scream|Someone's Taken T...|After a series of...|/3O3klyyYpAZBBE4n...|               en|  1996-12-20|    112| 66.1709976196289|      6578|7.421000003814697|Scream Someone's ...|\n",
      "|646385|Scream|It's always someo...|Twenty-five years...|/1m3W6cpgwuIyjtg5...|               en|  2022-01-12|    114|71.06199645996094|      3047|6.699999809265137|Scream It's alway...|\n",
      "+------+------+--------------------+--------------------+--------------------+-----------------+------------+-------+-----------------+----------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie.filter(F.col('title') == \"Scream\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self, movies):\n",
    "        self.movies = movies\n",
    "\n",
    "    def weighted_rating(self, v, R, m, C):\n",
    "        return (v / (v + m) * R) + (m / (m + v) * C)\n",
    "\n",
    "    def recommend(self, top_n=10):\n",
    "        C = self.movies.agg(F.avg('vote_average')).collect()[0][0]\n",
    "        m = self.movies.approxQuantile('vote_count', [0.9], 0.01)[0]\n",
    "        one_year_ago = F.current_date() - F.expr(\"INTERVAL 1 YEAR\")\n",
    "        filtered_movies = self.movies.filter((F.col('vote_count') >= m) & (F.col('release_date') >= one_year_ago))\n",
    "        score_movies = filtered_movies.withColumn('score_rating',\n",
    "                                                   self.weighted_rating(F.col('vote_count'), F.col('vote_average'), m, C))\n",
    "        score_movies = score_movies.orderBy(F.col('score_rating').desc()).limit(top_n)\n",
    "        return score_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+------------------+--------------------+------------------+\n",
      "|     id|               title|             tagline|            overview|         poster_path|original_language|release_date|runtime|        popularity|vote_count|      vote_average|     combined_column|      score_rating|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+------------------+--------------------+------------------+\n",
      "| 569094|Spider-Man: Acros...|It's how you wear...|After reuniting w...|/8Vt6mWEReuy4Of61...|               en|  2023-05-31|    140| 227.3280029296875|      6083| 8.399999618530273|Spider-Man: Acros...| 8.230673860792432|\n",
      "| 872585|         Oppenheimer|The world forever...|The story of J. R...|/8Gxv8gSFCU0XGDyk...|               en|  2023-07-19|    181| 490.4880065917969|      7514| 8.112000465393066|Oppenheimer The w...| 7.994503223290881|\n",
      "| 447365|Guardians of the ...|Once more with fe...|Peter Quill, stil...|/r2J02Z2OpNTctfOS...|               en|  2023-05-03|    150| 171.0800018310547|      6133| 7.974999904632568|Guardians of the ...|7.8461183608741765|\n",
      "| 906126| Society of the Snow|Based on a remark...|On October 13, 19...|/2e853FDVSIso600R...|               es|  2023-12-15|    144| 117.4800033569336|      2401| 8.065999984741211|Society of the Sn...| 7.759314548385597|\n",
      "| 678512|    Sound of Freedom|Fight for the lig...|The story of Tim ...|/qA5kPYZA7FkVvqcE...|               en|  2023-07-03|    131|124.05899810791016|      2082| 8.038999557495117|Sound of Freedom ...| 7.702365364014503|\n",
      "|1010581|            My Fault|                    |Noah must leave h...|/w46Vw536HwNnEzOa...|               es|  2023-06-08|    117| 305.9930114746094|      2400| 7.993000030517578|My Fault  Noah mu...| 7.701257460865559|\n",
      "| 792307|         Poor Things|She's like nothin...|Brought back to l...|/kCGlIMHnOm8JPXq3...|               en|  2023-12-07|    142| 416.6199951171875|      2934| 7.818999767303467|Poor Things She's...| 7.601531219629679|\n",
      "| 980489|        Gran Turismo|From gamer to racer.|The ultimate wish...|/51tqzRtKMMZEYUpS...|               en|  2023-08-09|    135|159.40699768066406|      2244|  7.86299991607666|Gran Turismo From...| 7.583632034401961|\n",
      "| 976573|           Elemental|    Opposites react.|In a city where f...|/4Y1WNkd88JXmGfht...|               en|  2023-06-14|    102|217.11900329589844|      3899| 7.664000034332275|Elemental Opposit...| 7.514293977181764|\n",
      "| 882569|Guy Ritchie's The...|A bond. A pledge....|During the war in...|/kVG8zFFYrpyYLoHC...|               en|  2023-04-19|    123| 90.51799774169922|      2179|7.7779998779296875|Guy Ritchie's The...|7.5110503086949265|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+-------+------------------+----------+------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommender = PopularityRecommender(movie)\n",
    "\n",
    "recommended_movies = recommender.recommend()\n",
    "recommended_movies.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "def combine_actor_character(actor, character):\n",
    "    return f\"{actor} playing {character}\"\n",
    "\n",
    "def combination_tto_characters_actors_directors(movie):\n",
    "    joined_data = crew.join(person, crew[\"person_id\"] == person[\"id\"], \"left\")\n",
    "    directors = joined_data.filter(F.col(\"job\") == \"Director\")\n",
    "    directors = directors.withColumn(\"directors_text\", F.concat_ws(\" \", F.lit(\"director filma\"), person.name))\n",
    "    directors = directors.select(crew.movie_id,'directors_text').groupBy(\"movie_id\").agg(\n",
    "        F.collect_list(\"directors_text\").alias(\"directors\")\n",
    "    )\n",
    "\n",
    "    joined_data = cast.join(person, cast[\"person_id\"] == person[\"id\"], \"left\")\n",
    "    window_spec = Window.partitionBy(\"movie_id\").orderBy(F.desc(\"popularity\"))\n",
    "    top_actors = (joined_data.withColumn(\"rank\", F.row_number().over(window_spec))\n",
    "                .filter(F.col(\"rank\") <= 3)\n",
    "                .select(cast.movie_id,cast.character,person.name.alias(\"actor_name\")))\n",
    "    combine_actor_character_udf = F.udf(combine_actor_character, StringType())\n",
    "    top_actors = top_actors.withColumn(\"actor_character_pairs\", combine_actor_character_udf(\"actor_name\", \"character\"))\n",
    "    top_actors = (top_actors.\n",
    "                groupBy(\"movie_id\").agg(\n",
    "                F.collect_list(\"actor_character_pairs\").alias(\"actors\")\n",
    "    ))\n",
    "\n",
    "    movie_actors = movie.join(top_actors, top_actors[\"movie_id\"] == movie[\"id\"], \"left\")\n",
    "    movie_actors_directors = movie_actors.join(directors,directors['movie_id'] == movie_actors['id'],'left')\n",
    "\n",
    "    movie_actors_directors = movie_actors_directors.select('id','title','tagline','overview','actors','directors')\n",
    "\n",
    "    movie_actors_directors = (movie_actors_directors\n",
    "                                    .withColumn(\"combined_column\",\n",
    "                                      F.concat_ws(\" \", *[F.col(c) for c in movie_actors_directors.columns if c != 'id'])))\n",
    "    \n",
    "    return movie_actors_directors.select('id','combined_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_actors_characters_directors = combination_tto_characters_actors_directors(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilaritySearch:\n",
    "    def __init__(self, description_var,spark):\n",
    "        self.spark = spark\n",
    "        self.description_var = description_var\n",
    "        self.tokenizer = RegexTokenizer(inputCol=description_var, outputCol=\"words\", pattern=\"\\\\W\")\n",
    "        self.remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "        self.hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "        self.idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "        self.normalizer = Normalizer(inputCol=\"features\", outputCol=\"normalized_features\")\n",
    "        self.pipeline = Pipeline(stages=[self.tokenizer, self.remover, self.hashing_tf, self.idf, self.normalizer])\n",
    "        self.postfix = 'right'\n",
    "    \n",
    "    def fit_transform(self, dataframe):\n",
    "        self.model = self.pipeline.fit(dataframe)\n",
    "        self.dataframe = self.transform(dataframe)\n",
    "        \n",
    "    \n",
    "    def transform(self, dataframe):\n",
    "        return self.model.transform(dataframe).drop('filtered_words', 'raw_features', 'words', 'features')\n",
    "    \n",
    "    def search(self,description_user:str,top_n = 5):\n",
    "        row = [{self.description_var: description_user}]\n",
    "        single_row_df = self.spark.createDataFrame(row)\n",
    "        transformed_single_row_df = self.transform(single_row_df)\n",
    "        \n",
    "        transformed_df = transformed_single_row_df.crossJoin(self.dataframe\n",
    "                                              .select([F.col(c).alias(f'{c}_{self.postfix}') for c in self.dataframe.columns]))\n",
    "        \n",
    "        transformed_df = transformed_df.withColumn('cos_sim', cos_sim(F.col('normalized_features'), F.col(f'normalized_features_{self.postfix}')))\n",
    "        \n",
    "        return transformed_df.orderBy(F.desc('cos_sim')).limit(top_n).select(F.col('id_right').alias('movie_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/15 23:34:20 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "[Stage 1310:===================================================>  (61 + 3) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "|  324857|\n",
      "|  569094|\n",
      "|     557|\n",
      "|  225925|\n",
      "|  225914|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "similarity_search = SimilaritySearch(\"combined_column\",spark)\n",
    "similarity_search.fit_transform(movie_actors_characters_directors)\n",
    "desc_terminator = \"Tobey Maguire plays peter parker. Kirsten Duns plays merry jane. Peter Parker is bitten by a radioactive spider.\"\n",
    "\n",
    "similar_movies = similarity_search.search(description_user=desc_terminator)\n",
    "similar_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
